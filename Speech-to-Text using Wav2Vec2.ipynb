{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09db5f28-f373-4720-9e0e-5141c48b5648",
   "metadata": {},
   "source": [
    "# Assignment: Speech to Text using Wav2Vec2\n",
    "\n",
    "**Objective**: Convert a recorded audio (.wav) into text using a pre-trained Wav2Vec2 model.\n",
    "\n",
    "## Steps Followed:\n",
    "- Installed required libraries (torch, torchaudio, librosa, transformers).\n",
    "- Loaded the pre-trained Facebook Wav2Vec2.0 model and processor.\n",
    "- Recorded/used my own audio file and resampled it to 16kHz.\n",
    "- Preprocessed the audio input.\n",
    "- Passed the audio through the model to generate transcription.\n",
    "- Output the transcription result successfully.\n",
    "\n",
    "## Result:\n",
    "The transcription of my audio was printed correctly without any errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319c20d1-e1d7-4043-b004-b57d183983d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\guntu\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\guntu\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\guntu\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Installing collected packages: soxr, audioread, soundfile, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchaudio librosa transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f223aa9-c126-4d81-aced-39bb22fa30e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Using cached sounddevice-0.5.1-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\guntu\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Using cached sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sounddevice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1f6b4-d524-4381-80fd-a7e3e102e053",
   "metadata": {},
   "source": [
    "### My Recorded Sentence:\n",
    "_\"Hello, this is Jack, it's lovely to meet you.\"_\n",
    "\n",
    "### Model's Transcription Output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1b803ba-1da8-48c3-a4b5-9fbb36d871f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Recording for 10 seconds...\n",
      "‚úÖ Recording saved as: recording_test.wav\n",
      "\n",
      "üîÑ Loading model and processor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n",
      "\n",
      "üéµ Loading audio from: recording_test.wav\n",
      "\n",
      "üìù Transcription Result:\n",
      "---------------------------------\n",
      "HI THIS IS JACK IT'S VERY LOUDLY TO MEET YOU ALL\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (if not installed)\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Step 1: Record Audio\n",
    "\n",
    "def record_audio(filename=\"recording_test.wav\", duration=5, fs=16000):\n",
    "    print(f\"üéôÔ∏è Recording for {duration} seconds...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "    sd.wait()\n",
    "    write(filename, fs, recording)\n",
    "    print(f\"‚úÖ Recording saved as: {filename}\")\n",
    "\n",
    "# Step 2: Load Model and Processor\n",
    "\n",
    "def load_model_and_processor():\n",
    "    print(\"\\nüîÑ Loading model and processor...\")\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\", ignore_mismatched_sizes=True)\n",
    "    print(\"‚úÖ Model loaded successfully!\\n\")\n",
    "    return processor, model\n",
    "\n",
    "# Step 3: Transcribe Audio\n",
    "\n",
    "def transcribe_audio(file_path, processor, model):\n",
    "    print(f\"üéµ Loading audio from: {file_path}\")\n",
    "    speech_array, sampling_rate = librosa.load(file_path, sr=16000)\n",
    "    # Normalize volume a little bit (optional but helps!)\n",
    "    speech_array = speech_array / max(abs(speech_array))\n",
    "    inputs = processor(speech_array, return_tensors=\"pt\", sampling_rate=16000)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    print(\"\\nüìù Transcription Result:\")\n",
    "    print(\"---------------------------------\")\n",
    "    print(transcription)\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "# Step 4: Execute Everything\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"recording_test.wav\"\n",
    "    duration = 10  # Record for 5 seconds (you can increase if you want)\n",
    "\n",
    "    # 1. Record\n",
    "    record_audio(filename=filename, duration=duration)\n",
    "\n",
    "    # 2. Load Model\n",
    "    processor, model = load_model_and_processor()\n",
    "\n",
    "    # 3. Transcribe\n",
    "    transcribe_audio(filename, processor, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc268305-d00e-4118-a0a1-659c7321fc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
